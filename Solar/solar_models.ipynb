{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T15:46:56.146327Z",
     "iopub.status.busy": "2022-12-13T15:46:56.145860Z",
     "iopub.status.idle": "2022-12-13T15:46:56.165596Z",
     "shell.execute_reply": "2022-12-13T15:46:56.164282Z",
     "shell.execute_reply.started": "2022-12-13T15:46:56.146286Z"
    },
    "gather": {
     "logged": 1729026313545
    },
    "id": "VwRkZBHKi4NH",
    "outputId": "cfd1cb93-c91f-412b-da46-9bc6de7bb3e6",
    "papermill": {
     "duration": 1.634616,
     "end_time": "2022-11-30T15:12:08.283686",
     "exception": false,
     "start_time": "2022-11-30T15:12:06.649070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pandas.tseries.offsets import DateOffset\n",
    "pd.options.mode.chained_assignment = None\n",
    "from neuralprophet import NeuralProphet\n",
    "#from prophet import Prophet\n",
    "import logging\n",
    "logging.getLogger('neuralprophet').disabled = True\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# models\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blob storage config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "gather": {
     "logged": 1729027101716
    }
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "account_name = 'ormatprdstorage1'\n",
    "account_key = '9n99wAvTcTVBVoANyf8SHJ9cG/VRmA1C2umiyPbHOXb8Bhs578oKQxeK1Sl1DHCVYhTWH+cmNVpPuC1+7EFo8Q==' #Renew in the end of 2024\n",
    "connection_string = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_name = 'azureml-blobstore-5930a3cf-9d2a-4c61-8e7c-3e55e29484ec'\n",
    "blob_storage_path = 'ML_Reasults'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Specific Plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "gather": {
     "logged": 1729027114498
    }
   },
   "outputs": [],
   "source": [
    "class SelectPlantTransformer(BaseEstimator, TransformerMixin):\n",
    "   #######\n",
    "    def __init__(self,plant):\n",
    "        self.plant=plant\n",
    "\n",
    "    def fit(self, X):  #\n",
    "        return self\n",
    "\n",
    "\n",
    "    def select_plant(self, df):\n",
    "        try:\n",
    "            #df.drop(df[df['Plant']!=self.plant].index, inplace = True)\n",
    "            df=df[df['Plant']==self.plant]\n",
    "\n",
    "            #print('Select plant: ' + self.plant)\n",
    "         \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.select_plant(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add previous n days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "gather": {
     "logged": 1729027439907
    }
   },
   "outputs": [],
   "source": [
    "class PreviousDaysTransformer(BaseEstimator, TransformerMixin):\n",
    "   #######\n",
    "    def __init__(self, num_of_days=5):\n",
    "        self.num_of_days = num_of_days\n",
    "\n",
    "    def fit(self, X):  #\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def add_days(self, df):\n",
    "        \n",
    "        def previous_day(df, i):\n",
    "            previous = pd.merge(df, df, left_on=f'prev_{i}', right_on=df.index, right_index=True, how='left')\n",
    "            previous.columns = previous.columns.str.rstrip('_x')\n",
    "            previous = previous.rename(columns={'Solar_y':f'Solar_{i}'})\n",
    "            previous = previous.drop([col for col in previous.columns if '_y' in col],axis=1)\n",
    "            return previous\n",
    "        \n",
    "        try:\n",
    "            df = df.set_index('DateTime')\n",
    "            for i in range(1,self.num_of_days+1):\n",
    "                df[f'prev_{i}'] = df.index - pd.DateOffset(days=i)\n",
    "                \n",
    "            previous_days = [previous_day(df, 1)]\n",
    "            \n",
    "            for i in range(2, self.num_of_days+1):\n",
    "                previous_days.append(previous_day(previous_days[i-2], i))\n",
    "                 \n",
    "            \n",
    "            df = previous_days[-1].drop([f'prev_{i}' for i in range(1,self.num_of_days+1)],axis=1)\n",
    "\n",
    "            # back fill NaN values\n",
    "            df[[f'Solar_{i}' for i in range(1,self.num_of_days+1)]] = df[[f'Solar_{i}' for i in range(1,self.num_of_days+1)]].bfill()\n",
    "            df = df.reset_index()\n",
    "            del previous_days\n",
    "            # print(f'previous {self.num_of_days} days added successfully')\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.add_days(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get last x days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "gather": {
     "logged": 1701856920523
    }
   },
   "outputs": [],
   "source": [
    "class LastXDaysTransformer(BaseEstimator, TransformerMixin):\n",
    "   #######\n",
    "    def __init__(self,num_of_days=''):\n",
    "        self.num_of_days=num_of_days\n",
    " \n",
    "    def fit(self, X):  #\n",
    "        return self\n",
    " \n",
    " \n",
    "    def get_last_x_days(self, df):\n",
    "        try:\n",
    "            if self.num_of_days!='':    \n",
    "                if 'DateTime' in df.columns:\n",
    "                    df = df.set_index('DateTime')\n",
    "                df = df[df.last_valid_index()-pd.DateOffset(self.num_of_days, 'D'):]\n",
    "                df = df.reset_index()\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "        return df\n",
    " \n",
    "    def transform(self, X):\n",
    "        X = self.get_last_x_days(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGJqWPb4i4Ni",
    "papermill": {
     "duration": 0.010658,
     "end_time": "2022-11-30T15:12:10.001790",
     "exception": false,
     "start_time": "2022-11-30T15:12:09.991132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # Add date attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T15:46:56.916572Z",
     "iopub.status.busy": "2022-12-13T15:46:56.916139Z",
     "iopub.status.idle": "2022-12-13T15:46:56.934701Z",
     "shell.execute_reply": "2022-12-13T15:46:56.933501Z",
     "shell.execute_reply.started": "2022-12-13T15:46:56.916537Z"
    },
    "gather": {
     "logged": 1701856930539
    },
    "id": "Ck-uMTbRi4Nj"
   },
   "outputs": [],
   "source": [
    "class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def add_date_attributes(self, df):\n",
    "        try:\n",
    "            df['DateTime']=pd.to_datetime(df['DateTime'], format='%d/%m/%Y %H:%M')\n",
    "            df['year'] = pd.DatetimeIndex(df['DateTime']).year\n",
    "            df['month'] = pd.DatetimeIndex(df['DateTime']).month\n",
    "            df['day'] = pd.DatetimeIndex(df['DateTime']).day\n",
    "            df['hour'] = pd.DatetimeIndex(df['DateTime']).hour\n",
    "            df['weekday'] = pd.DatetimeIndex(df['DateTime']).weekday\n",
    "            df['day_name'] = pd.DatetimeIndex(df['DateTime']).day_name()\n",
    "\n",
    "            df['day_part'] = pd.cut(df['hour'],[-1,6,16,25] , labels=['2','1', '3'] )## \n",
    "            df['day_part']=df['day_part'].str.replace('3', '2')\n",
    "            df['season']=pd.cut(df['month'], [0 ,2,5,9 ,11,12] , labels=['0','1','2','3','4'] )\n",
    "            df['season']=df['season'].str.replace('0', '4')\n",
    "            df['weekend']=pd.cut(df['weekday'], [-1,4,6] , labels=['1','2'] )\n",
    "\n",
    "           # df['retio']= df['Power']/df['Temp']\n",
    "           # df['std']=df['retio'].std()\n",
    "\n",
    "            #print('Date attributes add successfully')\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.add_date_attributes(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWcbK0f2i4Nh",
    "papermill": {
     "duration": 0.010378,
     "end_time": "2022-11-30T15:12:09.588912",
     "exception": false,
     "start_time": "2022-11-30T15:12:09.578534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T15:46:56.896075Z",
     "iopub.status.busy": "2022-12-13T15:46:56.895712Z",
     "iopub.status.idle": "2022-12-13T15:46:56.914401Z",
     "shell.execute_reply": "2022-12-13T15:46:56.912835Z",
     "shell.execute_reply.started": "2022-12-13T15:46:56.896028Z"
    },
    "gather": {
     "logged": 1701856927585
    },
    "id": "W-8O7pkBi4Ni"
   },
   "outputs": [],
   "source": [
    "class CleaningTransformer(BaseEstimator, TransformerMixin):\n",
    "   #######\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):  #\n",
    "        return self\n",
    "\n",
    "\n",
    "    def clean_data(self, df):\n",
    "        try:\n",
    "            df.drop(df[df['Temp']<0].index, inplace = True)\n",
    "            df.drop(df[df['Temp']>200].index, inplace = True)\n",
    "            df.dropna(subset = ['Temp'], inplace=True)\n",
    "\n",
    "            #print('Cleaned successfully')\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.clean_data(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTzJMZwLi4Nk"
   },
   "source": [
    "# Dummy Replace values to dummies (get_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T15:52:33.547217Z",
     "iopub.status.busy": "2022-12-13T15:52:33.546781Z",
     "iopub.status.idle": "2022-12-13T15:52:33.556296Z",
     "shell.execute_reply": "2022-12-13T15:52:33.554981Z",
     "shell.execute_reply.started": "2022-12-13T15:52:33.547181Z"
    },
    "gather": {
     "logged": 1701856935354
    },
    "id": "c-k2Z4QEi4Nl"
   },
   "outputs": [],
   "source": [
    "class DummyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self):\n",
    "         return self\n",
    "\n",
    "    def dummy(self, df):\n",
    "        df=df[['Temp','Solar','hour','weekday','day_part','season','weekend', 'Solar_1', 'Solar_2', 'Solar_3', 'Solar_4', 'Solar_5']]\n",
    "        df=pd.get_dummies(df,columns = ['hour','weekday','day_part','season','weekend'])\n",
    "        return df\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.dummy(X)\n",
    "        #print('Get Dummies successfully')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "gather": {
     "logged": 1701856943598
    }
   },
   "outputs": [],
   "source": [
    "class WeatherDataArrangeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def data_arrangement(self, df):\n",
    "        try:\n",
    "            df = df[df['Hour'] != 25]\n",
    "            df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
    "            df['DateTime'] = df['Date'] + pd.to_timedelta(df['Hour'].astype(str) + ':00:00')\n",
    "            df = df[['DateTime', 'Location', 'Value']].rename(columns={'Value':'Temp', 'Location':'Plant'})\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.data_arrangement(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Prophet data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPDataArrangeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def data_arrangement(self, df):\n",
    "        try:\n",
    "            df = df.sort_values(['DateTime']).reset_index(drop=True)\n",
    "            df = df[['DateTime','Solar']].rename(columns = {\"DateTime\": \"ds\",\"Solar\": \"y\"})\n",
    "            df = df.set_index('ds')\n",
    "            df = df.sort_index()\n",
    "            df = df.asfreq('h')\n",
    "            df['y'] = df['y'].bfill().ffill()\n",
    "            df = df.reset_index()\n",
    "            df = df.sort_index()\n",
    "\n",
    "            df[\"zero\"] = df[\"ds\"].apply(lambda x: x.hour not in [7,8,9,10,11,12,13,14,15,16])\n",
    "            df[\"value\"] = df[\"ds\"].apply(lambda x: x.hour in [7,8,9,10,11,12,13,14,15,16])\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.data_arrangement(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "gather": {
     "logged": 1701856946467
    }
   },
   "outputs": [],
   "source": [
    "class DaysForPredTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,last_date,days):\n",
    "        self.last_date=last_date\n",
    "        self.days = days\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def days_for_pred(self, df):\n",
    "        try:\n",
    "            # interpolation fill empty values\n",
    "            df['Temp'] = df['Temp'].interpolate(method='linear', limit_direction='forward')            \n",
    "            # Take x next days data for prediction\n",
    "            target_date_range = self.last_date + pd.DateOffset(days=self.days)\n",
    "            \n",
    "            df = df[(df['DateTime'] > last_date) & (df['DateTime'] <= target_date_range)]\n",
    "            #df = df[(df['DateTime'].dt.hour >= 5) & (df['DateTime'].dt.hour <= 19)]\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.days_for_pred(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Wf2aYgvi4NY"
   },
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T15:46:56.168908Z",
     "iopub.status.busy": "2022-12-13T15:46:56.167777Z",
     "iopub.status.idle": "2022-12-13T15:46:56.718613Z",
     "shell.execute_reply": "2022-12-13T15:46:56.717272Z",
     "shell.execute_reply.started": "2022-12-13T15:46:56.168841Z"
    },
    "gather": {
     "logged": 1701856950095
    },
    "id": "uugRHyCJi4Nb",
    "outputId": "408f10f4-a05e-4187-82f5-b06ae93ead50",
    "papermill": {
     "duration": 0.967463,
     "end_time": "2022-11-30T15:12:09.261461",
     "exception": false,
     "start_time": "2022-11-30T15:12:08.293998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "solar_df = pd.read_csv('https://ormatprdstorage1.blob.core.windows.net/azureml-blobstore-5930a3cf-9d2a-4c61-8e7c-3e55e29484ec/Azureml_Generation/Generation.csv?sp=rcw&st=2023-11-28T07:46:25Z&se=2024-12-31T15:46:25Z&spr=https&sv=2022-11-02&sr=c&sig=ZrQv6iSFtEFeKuZs8S1WhGBoQPRjmH7SJI%2BgeRxIu5Q%3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_df['Solar'] = solar_df['Solar'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6R-IUwONi4Nc",
    "papermill": {
     "duration": 0.011608,
     "end_time": "2022-11-30T15:12:09.283396",
     "exception": false,
     "start_time": "2022-11-30T15:12:09.271788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Date Column to DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T15:46:56.720266Z",
     "iopub.status.busy": "2022-12-13T15:46:56.719902Z",
     "iopub.status.idle": "2022-12-13T15:46:56.759117Z",
     "shell.execute_reply": "2022-12-13T15:46:56.757838Z",
     "shell.execute_reply.started": "2022-12-13T15:46:56.720232Z"
    },
    "gather": {
     "logged": 1701856952817
    },
    "id": "4pl-kNO3i4Nc",
    "outputId": "13391152-1b62-48c1-c196-487436fb32e5",
    "papermill": {
     "duration": 0.061981,
     "end_time": "2022-11-30T15:12:09.355495",
     "exception": false,
     "start_time": "2022-11-30T15:12:09.293514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "solar_df['DateTime']= pd.to_datetime(solar_df['DateTime'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "gather": {
     "logged": 1701856955879
    }
   },
   "outputs": [],
   "source": [
    "weather_forecast_data = pd.read_csv('https://ormatprdstorage1.blob.core.windows.net/azureml-blobstore-5930a3cf-9d2a-4c61-8e7c-3e55e29484ec/Azureml_Generation/Forecast.csv?sp=rcw&st=2023-11-28T07:46:25Z&se=2024-12-31T15:46:25Z&spr=https&sv=2022-11-02&sr=c&sig=ZrQv6iSFtEFeKuZs8S1WhGBoQPRjmH7SJI%2BgeRxIu5Q%3D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plants list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "gather": {
     "logged": 1701856962833
    }
   },
   "outputs": [],
   "source": [
    "plant_dict = {'Brady':'BRADY',\n",
    "              'Galena2':'GALENA 2',\n",
    "              'SBHR':'SBHills',\n",
    "              'SB2-3':'STEAMBOAT 2-3',\n",
    "              'Tungsten':'TUNGSTEN'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plant in plant_dict.keys():\n",
    "\n",
    "    solar = SelectPlantTransformer(plant).transform(solar_df)\n",
    "    solar = LastXDaysTransformer(90).transform(solar)\n",
    "    solar = NPDataArrangeTransformer().transform(solar)\n",
    "\n",
    "    # Initialize NeuralProphet model\n",
    "    model = NeuralProphet(\n",
    "            yearly_seasonality=False,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=True,\n",
    "            n_lags=5 * 24,\n",
    "            ar_layers=[32, 32, 32],\n",
    "            learning_rate=0.005,\n",
    "            n_forecasts=48)\n",
    "\n",
    "    model.add_seasonality(name=\"zero\", period=24, fourier_order=3, condition_name=\"zero\")\n",
    "    model.add_seasonality(name=\"value\", period=24, fourier_order=3, condition_name=\"value\")\n",
    "\n",
    "    model.fit(solar)\n",
    "    \n",
    "    future = model.make_future_dataframe(solar, periods=48)\n",
    "    future[\"zero\"] = future[\"ds\"].apply(lambda x: x.hour not in [7,8,9,10,11,12,13,14,15,16])\n",
    "    future[\"value\"] = future[\"ds\"].apply(lambda x: x.hour in [7,8,9,10,11,12,13,14,15,16])\n",
    "    forecast = model.predict(future)\n",
    "    forecast = model.get_latest_forecast(forecast)\n",
    "    # Set value to zero at hours without solar generation\n",
    "    forecast['origin-0'] = np.where(forecast['origin-0'] < 0.7, 0, forecast['origin-0'])\n",
    "    \n",
    "    dates = forecast['ds'].values\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'DateTime': dates,\n",
    "        'Plant': plant,\n",
    "        'Temp': 'null',\n",
    "        'Power': forecast['origin-0'].values\n",
    "    })\n",
    "    \n",
    "    # Convert 00 to 24\n",
    "    results['DateTime'] = results['DateTime'].apply(lambda x: x - pd.DateOffset(days=1) if x.hour == 0 else x)\n",
    "    results['DateTime'] = results['DateTime'].dt.strftime('%Y-%m-%d %H:00:00').str.replace(' 00:', ' 24:')\n",
    "    \n",
    "    csv_data = results.to_csv(index=False)\n",
    "    # Specify the blob name and upload the CSV data to the container:\n",
    "    blob_name = f\"{blob_storage_path}/solar_np_{plant}.csv\"\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "    blob_client.upload_blob(csv_data, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesRegressor & RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plant in plant_dict.keys():\n",
    "    # Select plant\n",
    "    solar = SelectPlantTransformer(plant).transform(solar_df)\n",
    "    # Add previous days \n",
    "    solar = PreviousDaysTransformer(5).transform(solar)\n",
    "    # get x last days\n",
    "    solar = LastXDaysTransformer(90).transform(solar)\n",
    "    # Clean\n",
    "    solar = CleaningTransformer().transform(solar)\n",
    "    solar = solar.sort_values(['DateTime']).reset_index(drop=True)\n",
    "    # Get last date for prediction\n",
    "    last_date = solar['DateTime'].max()\n",
    "    # Weather forcast data arrangement\n",
    "    weather_forecast =  WeatherDataArrangeTransformer().transform(weather_forecast_data)    \n",
    "    # Select plant in weather data\n",
    "    weather_forecast = SelectPlantTransformer(plant_dict[plant]).transform(weather_forecast)\n",
    "    # Prepare data for prediction\n",
    "    weather_forecast = DaysForPredTransformer(last_date,days=2).transform(weather_forecast)\n",
    "   \n",
    "    # Combine original data with prediction data\n",
    "    all_data = pd.concat([solar, weather_forecast], ignore_index=True)\n",
    "    \n",
    "    # Date Arrangement\n",
    "    all_data = DateTransformer().transform(all_data)\n",
    "    # Save date column for output \n",
    "    dates = all_data['DateTime']\n",
    "\n",
    "    # Add Dummy\n",
    "    all_data = DummyTransformer().transform(all_data)\n",
    "    \n",
    "    train_data = all_data.iloc[:-48]\n",
    "    test_data = all_data.iloc[-48:]\n",
    "\n",
    "    # Train test arrangement\n",
    "    y_train=train_data['Solar'] \n",
    "    X_train=train_data.drop('Solar', axis=1)\n",
    "\n",
    "    y_test=test_data['Solar'] \n",
    "    X_test=test_data.drop('Solar', axis=1)\n",
    "    \n",
    "    models = [ExtraTreesRegressor(n_jobs=-1, random_state=159),RandomForestRegressor(n_jobs=-1, random_state=159)]\n",
    "    m_names = ['ExtraTrees', 'RandomForest']\n",
    "    for m_name, model in enumerate (models): \n",
    "        model = model.fit(X_train, y_train)\n",
    "        # Loop over 2 days and predict\n",
    "        for i in range(2):\n",
    "            # Calculate the start and end indices for the current loop\n",
    "            start_idx = i * 24\n",
    "            end_idx = (i + 1) * 24  \n",
    "            # Get the data for the current loop\n",
    "            current_day = test_data.iloc[start_idx:end_idx]   \n",
    "            previous_day = all_data.iloc[current_day.index - 24]\n",
    "            previous_day = previous_day.reset_index(drop=True)\n",
    "            ind = current_day.index.values\n",
    "            current_day = current_day.reset_index(drop=True)\n",
    "            current_day[current_day.columns[2:7]] = previous_day[previous_day.columns[1:6]]\n",
    "            current_day['Solar']  = model.predict(current_day.drop('Solar', axis=1))\n",
    "            current_day = current_day.set_index(ind)\n",
    "            all_data.iloc[ind] = current_day\n",
    "        # Organize predictions columns\n",
    "        all_data_copy = all_data.copy()\n",
    "        all_data_copy['DateTime'] = dates\n",
    "        all_data_copy['Plant'] = plant\n",
    "        \n",
    "        predictions = all_data_copy[['DateTime','Plant','Temp','Solar']].rename(columns={'Solar':'Power'}).tail(48).reset_index(drop=True)\n",
    "        predictions['Power'] = predictions.apply(lambda x: x['Power'] if 7 <= x['DateTime'].hour <= 16 else 0, axis=1)\n",
    "        # Convert 00 to 24\n",
    "        predictions['DateTime'] = predictions['DateTime'].apply(lambda x: x - pd.DateOffset(days=1) if x.hour == 0 else x)\n",
    "        predictions['DateTime'] = predictions['DateTime'].dt.strftime('%Y-%m-%d %H:00:00').str.replace(' 00:', ' 24:')\n",
    "        \n",
    "        # save predictions to csv \n",
    "        csv_data = predictions.to_csv(index=False)\n",
    "        \n",
    "        # Specify the blob name and upload the CSV data to the container:\n",
    "        blob_name = f\"{blob_storage_path}/solar_{m_names[m_name]}_{plant}.csv\"\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "        blob_client.upload_blob(csv_data, overwrite=True)\n",
    "        print(\"saved successfuly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
